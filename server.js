// server.js
import dotenv from "dotenv";
dotenv.config();

import express from "express";
import cors from "cors";
import OpenAI from "openai";
import { qdrant } from "./qdrant.js";

const app = express();
const PORT = process.env.PORT || 3000;

// OpenAI í´ë¼ì´ì–¸íŠ¸ (ì„œë²„ì—ì„œë§Œ!)
const client = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

app.use(cors());
app.use(express.json());

// ì •ì  íŒŒì¼ ì œê³µ (public í´ë”)
app.use(express.static("public"));

async function analyzeQuery(userMessage) {
  const prompt = `
ë„ˆëŠ” ì‡¼í•‘ëª° ê²€ìƒ‰ì—”ì§„ì˜ ì¿¼ë¦¬ ë¶„ì„ê¸°ë‹¤.

ì‚¬ìš©ìžì˜ ì§ˆë¬¸ì„ ë³´ê³  ì•„ëž˜ JSON í˜•íƒœë¡œ ë³€í™˜í•´ë¼.
ë°˜ë“œì‹œ ì•„ëž˜ JSON ìŠ¤í‚¤ë§ˆë¥¼ ë”°ë¼ë¼:
{
  "search_text": string,
  "filters": {
    "max_price": number | null,
    "min_price": number | null,
    "brand": string | null,
    "category": string | null
  },
  "intent": string
}

ê·œì¹™:
- search_text: ë²¡í„° ê²€ìƒ‰ì— ì‚¬ìš©í•  ìžì—°ì–´ ë¬¸ìž¥ (1ë¬¸ìž¥)
- filters: ê°€ê²©, ë¸Œëžœë“œ, ì¹´í…Œê³ ë¦¬ ë“± ëª…í™•í•œ ì¡°ê±´
- must_not: ì œì™¸ ì¡°ê±´ (ì—†ìœ¼ë©´ ë¹ˆ ë°°ì—´)
- intent: ì‚¬ìš© ëª©ì  ìš”ì•½

JSON ì™¸ì˜ ë‹¤ë¥¸ ë§ì€ ì ˆëŒ€ í•˜ì§€ ë§ˆë¼.

ì‚¬ìš©ìž ì§ˆë¬¸:
"${userMessage}"
`;

  const response = await client.chat.completions.create({
    model: "gpt-4.1-mini",
    messages: [
      { role: "system", content: "ë„ˆëŠ” ê²€ìƒ‰ ì¿¼ë¦¬ ë¶„ì„ê¸°ë‹¤." },
      { role: "user", content: prompt },
    ],
    temperature: 0,
  });

  return JSON.parse(response.choices[0].message.content);
}

function buildQdrantFilter(filters) {
  const must = [];

  if (filters.max_price) {
    must.push({
      key: "price",
      range: { lte: filters.max_price },
    });
  }

  if (filters.brand) {
    must.push({
      key: "brand",
      match: { value: filters.brand },
    });
  }

  if (filters.category) {
    must.push({
      key: "category",
      match: { value: filters.category },
    });
  }

  return must.length ? { must } : undefined;
}

app.post("/chat", async (req, res) => {
  try {
    const { message } = req.body;

    // 1. ë‹ˆì¦ˆ ë¶„ì„
    const analyzed = await analyzeQuery(message);
    const { search_text, filters } = analyzed;

    // 2. ìž„ë² ë”© (1íšŒ)
    const embedding = await client.embeddings.create({
      model: "text-embedding-3-small",
      input: search_text,
    });

    // 3. Qdrant ê²€ìƒ‰
    const result = await qdrant.search("test_products", {
      vector: embedding.data[0].embedding,
      limit: 10,
      filter: buildQdrantFilter(filters),
    });

    res.json({
      analyzed,
      result,
    });
  } catch (e) {
    console.error(e);
    res.status(500).json({ error: "ê²€ìƒ‰ ì‹¤íŒ¨" });
  }
});

// ìž„ë² ë”©

app.post("/embedding", async (req, res) => {
  try {
    console.log(req)
    return;
    const embeddings = await openai.embeddings.create({
      model: "text-embedding-3-small",
      input: texts
    });
  } catch (err) {
    console.error(err);
    res.status(500).json({ error: "AI í˜¸ì¶œ ì‹¤íŒ¨" });
  }
});

app.listen(PORT, () => {
  console.log(`ðŸš€ Server running on http://localhost:${PORT}`);
});