// server.js
import dotenv from "dotenv";
dotenv.config();

import express from "express";
import cors from "cors";
import OpenAI from "openai";
import { qdrant } from "./qdrant.js";
import {
  buildQueryText,
  buildSparseVector,
  normalizeBrand,
  normalizeCategory,
} from "./searchUtils.js";

const app = express();
const PORT = process.env.PORT || 3000;

// OpenAI í´ë¼ì´ì–¸íŠ¸ (ì„œë²„ì—ì„œë§Œ!)
const client = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

app.use(cors());
app.use(express.json());

// ì •ì  íŒŒì¼ ì œê³µ (public í´ë”)
app.use(express.static("public"));

async function analyzeQuery(userMessage) {
  const prompt = `
ë„ˆëŠ” ì‡¼í•‘ëª° ê²€ìƒ‰ì—”ì§„ì˜ ì¿¼ë¦¬ ë¶„ì„ê¸°ë‹¤.

ì‚¬ìš©ìžì˜ ì§ˆë¬¸ì„ ë¶„ì„í•´ì„œ ì•„ëž˜ JSONìœ¼ë¡œ ë³€í™˜í•´ë¼.

JSON ìŠ¤í‚¤ë§ˆ:
{
  "semantic_query": string,
  "filters": {
    "max_price": number | null,
    "min_price": number | null,
    "brand": string | null,
    "category": string | null
  },
  "intent": string
}

ê·œì¹™:
- semantic_query:
  - ì‚¬ìš©ìžê°€ ë§í•œ í‘œí˜„ê³¼ ì˜ë¯¸ë¥¼ ìµœëŒ€í•œ ìœ ì§€í•œë‹¤
  - ê²€ìƒ‰ì— ë„ì›€ì´ ë˜ë„ë¡ ì˜ë¯¸ë¥¼ ìžì—°ìŠ¤ëŸ½ê²Œ ë³´ê°•í•œë‹¤
  - ë°˜ë“œì‹œ í•œ ë¬¸ìž¥ì¼ í•„ìš”ëŠ” ì—†ë‹¤
  - ì‚¬ìš©ìžê°€ ì–¸ê¸‰í•˜ì§€ ì•Šì€ ì •ë³´ëŠ” ì–µì§€ë¡œ ì¶”ê°€í•˜ì§€ ë§ˆë¼
  - ì§ˆë¬¸ì—ì„œ ì‚¬ìš©ìžê°€ ì›í•˜ëŠ” ë‹ˆì¦ˆì— ë§žëŠ” í‚¤ì›Œë“œë¥¼ ìš°ì„ ì ìœ¼ë¡œ ê³ ë ¤í•´ ìƒí’ˆì„ ì¡°íšŒí•´ì•¼í•œë‹¤.

- filters:
  - í™•ì‹¤í•œ ì¡°ê±´ë§Œ ì¶”ì¶œ
  - ì• ë§¤í•˜ë©´ null
- intent:
  - ì‚¬ìš©ìžì˜ ì‹¤ì œ ëª©ì ì„ í•œ ë¬¸ìž¥ìœ¼ë¡œ ìš”ì•½í•œë‹¤

JSON ì™¸ì˜ ë§ì€ ì ˆëŒ€ ì¶œë ¥í•˜ì§€ ë§ˆë¼.

ì‚¬ìš©ìž ì§ˆë¬¸:
"${userMessage}"
`;

  const response = await client.chat.completions.create({
    model: "gpt-4.1-mini",
    messages: [
      { role: "system", content: "ë„ˆëŠ” ê²€ìƒ‰ ì¿¼ë¦¬ ë¶„ì„ê¸°ë‹¤." },
      { role: "user", content: prompt },
    ],
    temperature: 0,
  });

  return { content: JSON.parse(response.choices[0].message.content), usage: response.usage };
}

function buildQdrantFilter(filters) {
  const must = [];

  if (filters.brand) {
    must.push({
      key: "brand",
      match: { value: filters.brand }
    });
  }

  if (filters.category) {
    must.push({
      key: "category",
      match: { value: filters.category }
    });
  }

  if (filters.min_price || filters.max_price) {
    must.push({
      key: "price",
      range: {
        gte: filters.min_price ?? undefined,
        lte: filters.max_price ?? undefined,
      }
    });
  }

  return must.length > 0 ? { must } : undefined;
}

async function searchQdrant({ denseVector, sparseVector, filters }) {
  const base = {
    limit: 5,
    score_threshold: 0.25,
    with_payload: true,
  };

  const hasSparse = sparseVector?.indices?.length > 0;
  const makePrefetch = (filter) => ([
    {
      query: { nearest: denseVector },
      using: "dense",
      limit: 50,
      filter,
    },
    ...(hasSparse ? [{
      query: { nearest: sparseVector },
      using: "sparse",
      limit: 50,
      filter,
    }] : []),
  ]);

  const runHybrid = async (filter) => qdrant.query("test_products", {
    prefetch: makePrefetch(filter),
    query: { fusion: "rrf" },
    limit: base.limit,
    score_threshold: base.score_threshold,
    with_payload: true,
    filter,
  });

  const strictFilter = buildQdrantFilter(filters);
  const resultStrict = await runHybrid(strictFilter);
  if (resultStrict?.length) return resultStrict;

  const relaxed = { ...filters, brand: null };
  const resultRelaxBrand = await runHybrid(buildQdrantFilter(relaxed));
  if (resultRelaxBrand?.length) return resultRelaxBrand;

  const relaxedCategory = { ...filters, category: null, brand: null };
  const resultRelaxCategory = await runHybrid(buildQdrantFilter(relaxedCategory));
  if (resultRelaxCategory?.length) return resultRelaxCategory;

  return runHybrid(undefined);
}

app.post("/chat", async (req, res) => {
  try {
    const { message } = req.body;
    // 1. ë‹ˆì¦ˆ ë¶„ì„
    const { content: analyzed, usage } = await analyzeQuery(message);
    const { semantic_query } = analyzed;
    const filters = {
      ...analyzed.filters,
      brand: normalizeBrand(analyzed.filters?.brand),
      category: normalizeCategory(analyzed.filters?.category),
    };

    // 2. ìž„ë² ë”© (1íšŒ)
    const queryText = buildQueryText({ semantic_query, filters, userMessage: message });
    const embedding = await client.embeddings.create({
      model: "text-embedding-3-small",
      input: queryText,
    });
    const sparseVector = buildSparseVector(queryText);

    // 3. Qdrant ê²€ìƒ‰
    const result = await searchQdrant({
      denseVector: embedding.data[0].embedding,
      sparseVector,
      filters,
    });

    res.json({
      analyzed,
      result: result,
      usage: embedding.usage
    });
  } catch (e) {
    console.error(e);
    res.status(500).json({ error: "ê²€ìƒ‰ ì‹¤íŒ¨" });
  }
});

// ìž„ë² ë”©

// app.post("/embedding", async (req, res) => {
//   try {
//     console.log(req)
//     return;
//     const embeddings = await openai.embeddings.create({
//       model: "text-embedding-3-small",
//       input: texts
//     });
//   } catch (err) {
//     console.error(err);
//     res.status(500).json({ error: "AI í˜¸ì¶œ ì‹¤íŒ¨" });
//   }
// });

app.listen(PORT, () => {
  console.log(`ðŸš€ Server running on http://localhost:${PORT}`);
});
