// server.js
import dotenv from "dotenv";
dotenv.config();

import express from "express";
import cors from "cors";
import OpenAI from "openai";
import { qdrant } from "./qdrant.js";

const app = express();
const PORT = process.env.PORT || 3000;

// OpenAI í´ë¼ì´ì–¸íŠ¸ (ì„œë²„ì—ì„œë§Œ!)
const client = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

app.use(cors());
app.use(express.json());

// ì •ì  íŒŒì¼ ì œê³µ (public í´ë”)
app.use(express.static("public"));

async function analyzeQuery(userMessage) {
  const prompt = `
ë„ˆëŠ” ì‡¼í•‘ëª° ê²€ìƒ‰ì—”ì§„ì˜ ì¿¼ë¦¬ ë¶„ì„ê¸°ë‹¤.

ì‚¬ìš©ìžì˜ ì§ˆë¬¸ì„ ë¶„ì„í•´ì„œ ì•„ëž˜ JSONìœ¼ë¡œ ë³€í™˜í•´ë¼.

JSON ìŠ¤í‚¤ë§ˆ:
{
  "semantic_query": string,
  "filters": {
    "max_price": number | null,
    "min_price": number | null,
    "brand": string | null,
    "category": string | null
  },
  "intent": string
}

ê·œì¹™:
- semantic_query:
  - ì‚¬ìš©ìžê°€ ë§í•œ í‘œí˜„ê³¼ ì˜ë¯¸ë¥¼ ìµœëŒ€í•œ ìœ ì§€í•œë‹¤
  - ê²€ìƒ‰ì— ë„ì›€ì´ ë˜ë„ë¡ ì˜ë¯¸ë¥¼ ìžì—°ìŠ¤ëŸ½ê²Œ ë³´ê°•í•œë‹¤
  - ë°˜ë“œì‹œ í•œ ë¬¸ìž¥ì¼ í•„ìš”ëŠ” ì—†ë‹¤
  - ì‚¬ìš©ìžê°€ ì–¸ê¸‰í•˜ì§€ ì•Šì€ ì •ë³´ëŠ” ì–µì§€ë¡œ ì¶”ê°€í•˜ì§€ ë§ˆë¼
  - ì§ˆë¬¸ì—ì„œ ì‚¬ìš©ìžê°€ ì›í•˜ëŠ” ë‹ˆì¦ˆì— ë§žëŠ” í‚¤ì›Œë“œë¥¼ ìš°ì„ ì ìœ¼ë¡œ ê³ ë ¤í•´ ìƒí’ˆì„ ì¡°íšŒí•´ì•¼í•œë‹¤.

- filters:
  - í™•ì‹¤í•œ ì¡°ê±´ë§Œ ì¶”ì¶œ
  - ì• ë§¤í•˜ë©´ null
- intent:
  - ì‚¬ìš©ìžì˜ ì‹¤ì œ ëª©ì ì„ í•œ ë¬¸ìž¥ìœ¼ë¡œ ìš”ì•½í•œë‹¤

JSON ì™¸ì˜ ë§ì€ ì ˆëŒ€ ì¶œë ¥í•˜ì§€ ë§ˆë¼.

ì‚¬ìš©ìž ì§ˆë¬¸:
"${userMessage}"
`;

  const response = await client.chat.completions.create({
    model: "gpt-4.1-mini",
    messages: [
      { role: "system", content: "ë„ˆëŠ” ê²€ìƒ‰ ì¿¼ë¦¬ ë¶„ì„ê¸°ë‹¤." },
      { role: "user", content: prompt },
    ],
    temperature: 0,
  });

  console.log(JSON.parse(response.choices[0].message.content))

  return { content: JSON.parse(response.choices[0].message.content), usage: response.usage };
}

function buildQdrantFilter(filters) {
  const must = [];

  if (filters.brand) {
    must.push({
      key: "brand",
      match: { value: filters.brand }
    });
  }

  // if (filters.category) {
  //   must.push({
  //     key: "category",
  //     match: { value: filters.category }
  //   });
  // }

  if (filters.min_price || filters.max_price) {
    must.push({
      key: "price",
      range: {
        gte: filters.min_price ?? undefined,
        lte: filters.max_price ?? undefined,
      }
    });
  }

  return must.length > 0 ? { must } : undefined;
}

app.post("/chat", async (req, res) => {
  try {
    const { message } = req.body;
    // 1. ë‹ˆì¦ˆ ë¶„ì„
    const { content: analyzed, usage } = await analyzeQuery(message);
    const { semantic_query, filters } = analyzed;

    // 2. ìž„ë² ë”© (1íšŒ)
    const embedding = await client.embeddings.create({
      model: "text-embedding-3-small",
      input: semantic_query,
    });

    console.log(buildQdrantFilter(filters))

    // 3. Qdrant ê²€ìƒ‰
    const result = await qdrant.search("test_products", {
      vector: embedding.data[0].embedding,
      limit: 1,
      filter: buildQdrantFilter(filters),
      // score_threshold: 0.55,
      with_payload: true,
    });
    console.log(result);

    res.json({
      analyzed,
      result: result,
      usage: embedding.usage
    });
  } catch (e) {
    console.error(e);
    res.status(500).json({ error: "ê²€ìƒ‰ ì‹¤íŒ¨" });
  }
});

// ìž„ë² ë”©

// app.post("/embedding", async (req, res) => {
//   try {
//     console.log(req)
//     return;
//     const embeddings = await openai.embeddings.create({
//       model: "text-embedding-3-small",
//       input: texts
//     });
//   } catch (err) {
//     console.error(err);
//     res.status(500).json({ error: "AI í˜¸ì¶œ ì‹¤íŒ¨" });
//   }
// });

app.listen(PORT, () => {
  console.log(`ðŸš€ Server running on http://localhost:${PORT}`);
});